{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import pickle\n",
        "# context = notebook, import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "from src import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|===============     | 1053/1414 [00:18<00:06]       "
          ]
        }
      ],
      "source": [
        "\n",
        "folder = '../data/processed/'\n",
        "\n",
        "datasets = ['dv2', 'dv3', 'dv2_humanized']\n",
        "df = pd.read_csv(folder + 'updated_moral_turing.csv')\n",
        "# rename identification to belief\n",
        "df = df.rename(columns={'identification': 'belief'})\n",
        "data = {}\n",
        "\n",
        "for ds in tqdm(datasets):\n",
        "\n",
        "    for col_name in ['source', 'belief', 'agree2']:\n",
        "        rs = 12345  # Random state\n",
        "\n",
        "        target_names = ['0', '1']\n",
        "        df_ = df[df['dataset'] == ds].copy()\n",
        "\n",
        "        # if col_name == 'agree' or col_name == 'agree2':\n",
        "            # df_['binary_label'] = np.where(df_[col_name] == 1, 1, 0)\n",
        "        # elif col_name == 'label':\n",
        "            # df_['binary_label'] = np.where(df_['source'] == 'AI', 1, 0)\n",
        "        # else:\n",
        "            # df_['binary_label'] = np.where(df_[col_name] == 'AI', 1, 0)\n",
        "        if col_name == 'agree2':\n",
        "            df_['binary_label'] = (df_[col_name] == 1).astype(int)\n",
        "        else:\n",
        "            df_['binary_label'] = (df_[col_name] == 'AI').astype(int)\n",
        "\n",
        "        df_1 = df_[df_['binary_label'] == 1]\n",
        "        df_0 = df_[df_['binary_label'] != 1]\n",
        "\n",
        "        # Downsample\n",
        "        if len(df_1) > len(df_0):\n",
        "            df_1_downsampled = df_1.sample(n=len(df_0), random_state=rs)\n",
        "            df_balanced = pd.concat([df_1_downsampled, df_0])\n",
        "        else:\n",
        "            df_0_downsampled = df_0.sample(n=len(df_1), random_state=rs)\n",
        "            df_balanced = pd.concat([df_0_downsampled, df_1])\n",
        "\n",
        "        df2 = df_balanced.sample(frac=1, random_state=rs).reset_index(drop=True)\n",
        "        X = df2['response']\n",
        "        y = df2['binary_label']\n",
        "\n",
        "        # Clean up stop words\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            stop_words='english',\n",
        "            # Only include words with letters (exclude numbers)\n",
        "            token_pattern=r'\\b[a-zA-Z][a-zA-Z]+\\b',\n",
        "            min_df=3,\n",
        "            max_features=1000\n",
        "        )\n",
        "        X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_tfidf, y, test_size=0.2, random_state=rs)\n",
        "\n",
        "        # Train a classifier\n",
        "        X_train_dense = X_train.toarray()\n",
        "        X_test_dense = X_test.toarray()\n",
        "\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=rs)\n",
        "        clf.fit(X_train_dense, y_train)\n",
        "\n",
        "        y_pred = clf.predict(X_test_dense)\n",
        "        report = classification_report(\n",
        "            y_test, y_pred, target_names=target_names)\n",
        "        e3 = shap.TreeExplainer(clf, X_train_dense)\n",
        "\n",
        "        sv3 = e3.shap_values(X_test_dense)\n",
        "        \n",
        "        if ds not in data:\n",
        "            data[ds] = {}\n",
        "        \n",
        "        if col_name not in data[ds]:\n",
        "            data[ds][col_name] = {}\n",
        "\n",
        "        data[ds][col_name]['shap'] = sv3\n",
        "        data[ds][col_name]['feature_names'] = vectorizer.get_feature_names_out()\n",
        "        data[ds][col_name]['dense'] = X_test_dense\n",
        "\n",
        "# save the data\n",
        "with open(folder + 'shap_data.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "'return' outside function (697329217.py, line 33)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "# import shap again\n",
        "import pickle\n",
        "from src import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "from src import shap\n",
        "\n",
        "sns.set_context('talk')\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "# best palettes \n",
        "# palette = ['dark:blue', 'dark:orange']\n",
        "# get cmap of viridis\n",
        "cmap_green = sns.color_palette('dark:#5f9e6e', as_cmap=True)\n",
        "cmap_blue = sns.color_palette('dark:#c44e52', as_cmap=True)\n",
        "cmap_orange = sns.color_palette('dark:#854e9e', as_cmap=True)\n",
        "\n",
        "# Plot SHAP values for each class\n",
        "#for i, class_name in enumerate(['1']):\n",
        "# load data if exists\n",
        "folder = '../data/processed/'\n",
        "try:\n",
        "    with open(folder + 'shap_data.pkl', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found\")\n",
        "    print('Please run the previous cell to generate the data')\n",
        "    raise Exception\n",
        "\n",
        "\n",
        "plt.figure(figsize=(100, 100), dpi=300)\n",
        "count = 0\n",
        "\n",
        "sources = ['dv2', 'dv3', 'dv2_humanized']\n",
        "\n",
        "for col_name in ['source', 'belief', 'agree2']:\n",
        "    for source, cmap in zip(sources, [cmap_blue, cmap_green, cmap_orange]):\n",
        "        count += 1\n",
        "        print(f\"Source: {source}, column: {col_name}\")\n",
        "        sv3 = data[source][col_name]\n",
        "        i = 0\n",
        "        class_name = '1'\n",
        "        \n",
        "        shap_values = data[source][col_name]['shap']\n",
        "        X_test_dense = data[source][col_name]['dense']\n",
        "        feature_names = data[source][col_name]['feature_names']\n",
        "\n",
        "\n",
        "        print(f\"SHAP values for class '{class_name}':\")\n",
        "\n",
        "        # shap.summary_plot(sv3[:, :, i], features=X_test_dense, feature_names=vectorizer.get_feature_names_out())\n",
        "        plt.subplot(3, 3, count)\n",
        "        \n",
        "        # color_bar = count % 3 == 0\n",
        "        color_bar = False\n",
        "\n",
        "        ax = shap.summary_plot(shap_values=shap_values[:, :, 1], features=X_test_dense,\n",
        "                           feature_names=feature_names,\n",
        "                            max_display=10, class_names=[f'Not {source}', source], plot_size=(12, 12), color=cmap, cmap=cmap,\n",
        "                             color_bar=color_bar, alpha=1, show=False) #get viridis colors\n",
        "        if col_name == 'source' or col_name == 'belief':\n",
        "            ax.set_xlabel(f\"importance in predicting AI \\n ({col_name})\")\n",
        "        else:\n",
        "            ax.set_xlabel(f\"importance in predicting \\nagreement\")\n",
        "            \n",
        "        xticks = ax.get_xticklabels()\n",
        "        # round to 1 decimal\n",
        "        try:\n",
        "            xticks = [x.get_text()[:len(x.get_text())-1]  if len(x.get_text().replace(\"-\", \"\")) > 4 else x.get_text() for x in xticks]\n",
        "            # print(xticks)\n",
        "            xticks = [\"0\" if x in (\"0.00\", \"0.0\") else x for x in xticks]\n",
        "            ax.set_xticklabels(xticks)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "        if count in [1, 2, 3]:\n",
        "            ax.set_title(f\"{source.replace('_', ' ')}\")\n",
        "\n",
        "        # set color bar label\n",
        "        if color_bar:\n",
        "            try:\n",
        "                ax.collections[0].colorbar.set_label('Word frequency')\n",
        "            # set larger bar width\n",
        "                ax.collections[0].colorbar.ax.set_aspect(10)\n",
        "            except AttributeError:\n",
        "                pass\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# reduce white space between subplots\n",
        "plt.subplots_adjust(wspace=0.55, hspace=0.4)\n",
        "            # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['source', 'belief', 'agree2'])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['dv2'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "provenance": [
        {
          "file_id": "11C-2mQqm9kbA03F5F_AfuQSGxUj8nlPb",
          "timestamp": 1725831679374
        },
        {
          "file_id": "1Xty619-1B4iyIUhxqsv_hU9rl_2U4Ijs",
          "timestamp": 1722992021880
        },
        {
          "file_id": "1TVuR48RHl7tvQ64pzVBujC8oT0EzcXU4",
          "timestamp": 1722990224193
        },
        {
          "file_id": "1MARTjc2fqMjeWHLUm-ARm-8AsANUYfpI",
          "timestamp": 1722918428507
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
